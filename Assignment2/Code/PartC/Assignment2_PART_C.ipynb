{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ipnWvssmbh7"
   },
   "source": [
    "# Transfer Learning on your Own Dataset\n",
    "\n",
    "You will get to use the power of Transfer learning with **your own dataset**. So in this assignment you are going to retrain the pre-trained VGG16 Model with your own detectable objects. \n",
    "\n",
    "![](https://miro.medium.com/max/1000/0*xNjEPIZmPvKeqss6)\n",
    "\n",
    "For doing so, you should :\n",
    "\n",
    "* Generate a custom dataset, so take your own images from custom objects (or from the team members).  \n",
    "\n",
    "* Be sure that you take the images from different angles and different distances, different lighting conditions and different backgrounds for each object. In other words, changing the environment where your objects are while training will lead to a better performance (generalization).\n",
    "\n",
    "* Use at least 3 diffent opbjects (3 classes) and at most 10 classes where such dataset should have at least 50-100 images per class. (more images should lead to better detection performance) \n",
    "\n",
    "* Follow the workflow as [decribed before](https://keras.io/guides/transfer_learning/)\n",
    "\n",
    "* Show the output of the different (training) steps and the resulting classification on unseen data and answer the related questions in the subsections below\n",
    "\n",
    "---\n",
    "\n",
    "### Use the following websites that take you trought all the steps of development.\n",
    "\n",
    "The first page explains how to use the VGG-16 model with Keras to classify pre-tained images. \n",
    "> https://machinelearningmastery.com/use-pre-trained-vgg-model-classify-objects-photographs/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This second page explains the complete proces for classification of images using Keras, they start a problem desciption, data praparation, building a custom CNN model and then optimizing this model. After this they look at the same problem solving it with transfer learning. \n",
    "\n",
    "> https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/\n",
    "\n",
    "\n",
    "You can start at the **\"Explore Transfer Learning\"** chapter, although you probably need to look back at earlier parts of this page.  \n",
    "\n",
    "| NOTE: Finetuning by retraining all weights in the network as described in the workflow is Optional |\n",
    "| --- |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Imad Hanzaz, Yannick Urselmann, Jaylong Verschuren\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOH78U5DpU5k"
   },
   "source": [
    "# Initialization\n",
    "\n",
    "load all needed libraries and functions, \n",
    "check the previous tutorial how to correctly load keras and other modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Of4Qf_7DpXOS"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "import imghdr\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "\n",
    "print(\"Current Tensorflow version used is: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWrbNzmtuhKG"
   },
   "source": [
    "# Load dataset & Plot a subset\n",
    "\n",
    "load your dataset and show a plot of the subset of your data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTZNxjTkul9u"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train_data_dir = pathlib.Path(\"./trainDataset\")\n",
    "test_data_dir = pathlib.Path(\"./testDataset\")\n",
    "\n",
    "image_count_train = len(list(train_data_dir.glob('*/*.png')))\n",
    "image_count_test = len(list(test_data_dir.glob('*/*.png')))\n",
    "\n",
    "print('Train set batch size = ' + str(image_count_train))\n",
    "print('Test set batch size = ' + str(image_count_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "truck = list(train_data_dir.glob('truck/*'))\n",
    "PIL.Image.open(str(truck[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "# train_data_dir = \"./trainDataset\"\n",
    "\n",
    "image_extensions = [\".png\", \".jpg\"]  # add there all your images file extensions\n",
    "\n",
    "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "for filepath in Path(train_data_dir).rglob(\"*\"):\n",
    "    if filepath.suffix.lower() in image_extensions:\n",
    "        img_type = imghdr.what(filepath)\n",
    "        if img_type is None:\n",
    "            print(f\"{filepath} is not an image\")\n",
    "        elif img_type not in img_type_accepted_by_tf:\n",
    "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "# test_data_dir = \"./testDataset\"\n",
    "# image_extensions = [\".png\", \".jpg\"]  # add there all your images file extensions\n",
    "\n",
    "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "for filepath in Path(test_data_dir).rglob(\"*\"):\n",
    "    if filepath.suffix.lower() in image_extensions:\n",
    "        img_type = imghdr.what(filepath)\n",
    "        if img_type is None:\n",
    "            print(f\"{filepath} is not an image\")\n",
    "        elif img_type not in img_type_accepted_by_tf:\n",
    "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# train data\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=image_count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class_names_train = train_ds.class_names\n",
    "print(class_names_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=image_count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class_names_test = test_ds.class_names\n",
    "print(class_names_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-P5qhvGumPu"
   },
   "source": [
    "# Prepare Data\n",
    "\n",
    "pre-process your raw input data... rescale... normalize...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    x_train = image_batch\n",
    "    y_train = labels_batch\n",
    "\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train, 10)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "y_train_onehot = np.array(y_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in test_ds:\n",
    "    x_test = image_batch\n",
    "    y_test = labels_batch\n",
    "\n",
    "y_test_onehot = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "y_test_onehot = np.array(y_test_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yal9uYElv_nU"
   },
   "source": [
    "## Define your Model\n",
    "\n",
    "With Transfer learning you take a given network model withouth the last layers, you can take the suggested VGG-16 model as decribed on the given website and add the additional layers. \n",
    "\n",
    "**NOTE:**\n",
    "That the Ouput layer should match your input dataset!\n",
    "\n",
    "\n",
    "\n",
    "* How is your model constructed, how many trainable parameters does it have, and where are they located?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZTFT_GJv_3N"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))   ## Loading VGG16 model\n",
    "base_model.trainable = False    ## Not trainable weights\n",
    "\n",
    "print(base_model.summary())\n",
    "\n",
    "## Preprocessing input\n",
    "x_train = preprocess_input(x_train) \n",
    "x_test = preprocess_input(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "flatten_layer = tf.keras.layers.Flatten()\n",
    "dense_layer_1 = tf.keras.layers.Dense(50, activation='relu')\n",
    "dense_layer_2 = tf.keras.layers.Dense(20, activation='relu')\n",
    "prediction_layer = tf.keras.layers.Dense(5, activation='softmax')\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    dense_layer_1,\n",
    "    dense_layer_2,\n",
    "    prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5t5_38HupW3"
   },
   "source": [
    "# Fit the Model\n",
    "\n",
    "Fitting the model is the time consuming part, this depend on the complexity of the model and the amount of training data. With Transfer learning a lot of pre-trained parameters are now 'frozen', this will limit training time (or enables us to train more complex networks with the same processing performance, and so achieving better results)\n",
    "\n",
    "* Which batch size and how many epochs give a good result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rycO-mp9uscG"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
    "\n",
    "model.fit(x_train, y_train_onehot, epochs=50, validation_split=0.2, batch_size=32, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdzrdzNeusno"
   },
   "source": [
    "# Evaluate Model\n",
    "\n",
    "Show the model accuracy after the training process ... \n",
    "* How accurate is your final model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Vk7p7YnuvR_"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRjQRnYluvaH"
   },
   "source": [
    "# learning curves\n",
    "\n",
    "Show the learning curves of your training sequence, of accuracy, value_accuracy and loss, value_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhWeZxmauyCe"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8a1ovA8uyMX"
   },
   "source": [
    "# Save model\n",
    "\n",
    "Save the model for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quPWuPwtu3s4"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbK5-OQ4u32A"
   },
   "source": [
    "# Evaluate Final Model\n",
    "\n",
    "After training and saving the model you can deploy this model on any given input image. You can start a new application in where you import this model and apply it on any given imput images, so you can just load the model and don't need the timeconsuming training anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zy3j_jLn4I6u"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqEeHGjG3fsd"
   },
   "source": [
    "# Make Prediction\n",
    "\n",
    "We can use our saved model to make a prediction on new images that are not trained on... make sure the input images receive the same pre-processing as the images you trained on.\n",
    "\n",
    "So fetch some images from the internet (similar classes, but not from your dataset), prepare them to fit your network and classify them. Do this for  **10 images per class** and show the results!\n",
    "\n",
    "* How good is the detection on you real dataset? (show some statistics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNpwYE5Ru8gn"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Questions\n",
    "* Explain what your input object represents and how the result should be classified\n",
    "* Explain the pre-processing steps of the object training image(s) before you can feed it to the network.\n",
    "* What features do you think are extracted (relevant)?\n",
    "* Show (in report and video) how accurate your predicted model is, how does your detection behave in other unseen situations? Also explain in what situation and why it does (not) perform well. Supported your statements by measurement data!\n",
    "* Explain the parameters that you used for re-training this network?\n",
    "* This example uses a custom (but pre-trained) network architecture, explain how it works and why it is build up this way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning\n",
    "Finetuning by retraining all weights in the network as described in the workflow is Optional, but this will lead to a better accuracy of your final model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanni\\AppData\\Local\\Microsoft\\WindowsApps\\python3.10.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanni/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d18f53f9c896a2b8bb565adf491d4ea47a0151f3ca6dbc95552d117e45cb145"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
